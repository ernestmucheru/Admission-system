{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ernestmucheru/Admission-system/blob/master/ICKB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwaLK4kD1Uar"
      },
      "source": [
        "#Introduction\n",
        "This notebook is a research and test model to explore the possibility of having our own internal chatbot at Cellulant powered using GPT 3.5-turbo running on our own internal knowledge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD4Qzglp3J-h"
      },
      "source": [
        "#Linking the data to feed the model with \n",
        "For the demonstration purposes we are going to use a temporary guthub repo as our knowledge base.\n",
        "\n",
        "This research is still in the initial stages and there's still a chance to package this in a more consumable manner that easily allows CRUD operations and permissions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cCyU-vV5Yb0",
        "outputId": "2b3e9519-9466-445d-da33-5d93f695cf67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'context_data' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/ernestmucheru/context_data.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiUyHP4T2g5F"
      },
      "source": [
        "# Install the dependicies\n",
        "Run the code below to install the depencies we need for our functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6LL4rxT6_W7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b056c9-2b89-4d6b-d58a-f691f6c37c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.5.16.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.9/175.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dataclasses_json\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Collecting langchain>=0.0.123\n",
            "  Downloading langchain-0.0.141-py3-none-any.whl (540 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.8/540.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from llama-index) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.9/dist-packages (from llama-index) (8.2.2)\n",
            "Collecting openai>=0.26.4\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from llama-index) (1.5.3)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama-index) (6.0)\n",
            "Collecting async-timeout<5.0.0,>=4.0.0\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama-index) (2.27.1)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting SQLAlchemy<2,>=1\n",
            "  Downloading SQLAlchemy-1.4.47-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gptcache>=0.1.7\n",
            "  Downloading gptcache-0.1.11-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openapi-schema-pydantic<2.0,>=1.2\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain>=0.0.123->llama-index) (1.10.7)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->llama-index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken->llama-index) (2022.10.31)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->llama-index) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->llama-index) (22.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.9/dist-packages (from gptcache>=0.1.7->langchain>=0.0.123->llama-index) (5.3.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses_json->llama-index) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain>=0.0.123->llama-index) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain>=0.0.123->llama-index) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain>=0.0.123->llama-index) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain>=0.0.123->llama-index) (1.26.15)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain>=0.0.123->llama-index) (2.0.2)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: llama-index\n",
            "  Building wheel for llama-index (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-index: filename=llama_index-0.5.16-py3-none-any.whl size=260612 sha256=b0b23b478e1022f1458869e9e4add4f28bbfec169a5388b131c6be745e2f8fc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/fe/f0/83d05ef4219e58526b3ead03d07bd379d97e9305da7eb36cf3\n",
            "Successfully built llama-index\n",
            "Installing collected packages: SQLAlchemy, mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, tiktoken, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses_json, aiohttp, openai, gptcache, langchain, llama-index\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.9\n",
            "    Uninstalling SQLAlchemy-2.0.9:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.9\n",
            "Successfully installed SQLAlchemy-1.4.47 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses_json-0.5.7 frozenlist-1.3.3 gptcache-0.1.11 langchain-0.0.141 llama-index-0.5.16 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openai-0.27.4 openapi-schema-pydantic-1.2.4 tiktoken-0.3.3 typing-inspect-0.8.0 yarl-1.8.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (0.0.141)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: gptcache>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.1.11)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.4.47)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.9/dist-packages (from gptcache>=0.1.7->langchain) (5.3.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (from gptcache>=0.1.7->langchain) (0.27.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai->gptcache>=0.1.7->langchain) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbuYetOy25eM"
      },
      "source": [
        "# Define the functions\n",
        "The following code defines the functions we need to construct the index and query it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UelAqQgk_yIt"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper, ServiceContext\n",
        "from langchain import OpenAI\n",
        "import sys\n",
        "import os\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def construct_index(directory_path):\n",
        "    # set maximum input size\n",
        "    max_input_size = 4096\n",
        "    # set number of output tokens\n",
        "    num_outputs = 2000\n",
        "    # set maximum chunk overlap\n",
        "    max_chunk_overlap = 20\n",
        "    # set chunk size limit\n",
        "    chunk_size_limit = 600 \n",
        "\n",
        "    # define prompt helper\n",
        "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
        "\n",
        "    # define LLM\n",
        "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n",
        " \n",
        "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
        "    \n",
        "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
        "    index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)\n",
        "\n",
        "    index.save_to_disk('index.json')\n",
        "\n",
        "    return index\n",
        "\n",
        "def ask_ai():\n",
        "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
        "    while True: \n",
        "        query = input(\"What do you want to ask? \")\n",
        "        response = index.query(query)\n",
        "        display(Markdown(f\"Response: <b>{response.response}</b>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz1jp33jGumu"
      },
      "source": [
        "# Set OpenAI API Key\n",
        "You need an OPENAI API key to be able to run this code.\n",
        "\n",
        "If you don't have one yet, get it by [signing up](https://platform.openai.com/overview). Then click your account icon on the top right of the screen and select \"View API Keys\". Create an API key.\n",
        "\n",
        "Then run the code below and paste your API key into the text input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RoJHE4fsAT3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95892b4-6ad3-4f2a-a0a1-73be8c56d9b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your OpenAI key here and hit enter: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\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = input(\"Paste your OpenAI key here and hit enter:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVrddlAL4I_v"
      },
      "source": [
        "#Construct an index\n",
        "Now we are ready to construct the index. This will take every file in the folder 'data', split it into chunks, and embed it with OpenAI's embeddings API.\n",
        "\n",
        "**Notice:** running this code will cost you credits on your OpenAPI account ($0.02 for every 1,000 tokens). If you've just set up your account, the free credits that you have should be more than enough for this experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kCYTE2EqBB7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c97e5b-4181-4b71-df9d-af4fdfa61680"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<llama_index.indices.vector_store.vector_indices.GPTSimpleVectorIndex at 0x7f91ac38fa30>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "construct_index(\"context_data/data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipJ_gYxN5cWh"
      },
      "source": [
        "#Ask questions\n",
        "It's time to have fun and test our AI. Run the function that queries GPT and type your question into the input. \n",
        "\n",
        "Our test knowledge base currently contains information regarding to our Group People Policies. Ask the model any question in regards to our policies: E.g\n",
        "1. What kind of leaves does Cellulant offer?\n",
        "2. How many leave days I'm I entitled to?\n",
        "3. And so on...\n",
        "\n",
        "Reach out to ernest.mucheru@cellulant.io for any further queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "s_uwsPGEIGsb",
        "outputId": "eb224ce4-1b14-4ab3-c6d8-55adaaa75f45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What do you want to ask? How many leave days I'm I entiltled to?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Response: <b>\n\nThe number of leave days you are entitled to depends on the country of residence of the employee and the Employment Act of that country. Generally, you are entitled to a maximum of 30 days of sick leave at full pay in the case of illness or other incapacity and to an additional 30 days at half pay in a period of 12 months. You are also entitled to five consecutive paid family responsibility leave days per annual leave cycle, three months' maternity leave, and time off for pre-natal appointments. Additionally, you may be eligible for an annual increase process and performance bonus while on maternity leave, and you may not work for six weeks after the birth of the child unless a medical practitioner certifies that you are fit to do so. On return to work, you must return on no less favourable terms and conditions of employment as those you had enjoyed before commencing maternity leave.</b>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "ask_ai()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}